<!DOCTYPE html>
<html lang="en">
<head>
  <link rel="shortcut icon" href="./favicon.ico" type="image/x-icon">

  <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/academicons@1.9.4/css/academicons.min.css">

  <meta charset="utf-8">
  <meta name="description" content="DualReal: Adaptive Joint Training for Lossless Identity-Motion Fusion in Video Customization">
  <!-- 简化社交媒体元信息 -->
  <meta property="og:title" content="DualReal: Video Customization Framework"/>
  <meta property="og:description" content="Achieving identity-motion fusion through adaptive joint training"/>
  <meta property="og:image" content="<image-banner-social>">

  <meta name="twitter:card" content="summary_large_image">
  <meta name="keywords" content="video generation, deep learning, identity preservation">
  <meta name="viewport" content="width=device-width, initial-scale=1">

  <title>DualReal</title>
  
  <!-- 简化样式表 -->
  <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/bulma@0.9.4/css/bulma.min.css">

  <style>
    /* 参考网站基础样式 */
    body {
      font-family: 'Georgia', serif;
      line-height: 1.6;
      color: #333;
    }
    
    .section {
      padding: 4rem 1.5rem;
    }
    
    .title {
      font-weight: 600;
      margin-bottom: 1.5rem;
    }
    
    .paper-title {
      font-size: 2.4rem;
      line-height: 1.3;
      margin-bottom: 1.4rem;
    }

    .author-list {
      font-size: 1.3rem;
      margin: 1.5rem 0;
    }

    .content-block {
      max-width: 1000px;
      margin: 0 auto;
    }

    .video-container {
      position: relative;
      padding-bottom: 56.25%;
      margin: 2rem 0;
    }

    .video-container iframe {
      position: absolute;
      width: 100%;
      height: 100%;
    }

    /* 修改图片容器样式 */
    .teaser-image {
        margin: 4rem auto 3rem;  /* 增加上下边距 */
        max-width: 1600px;      /* 增大最大宽度 */
        padding: 0 2rem;        /* 增加水平内边距 */
    }

    .teaser-image img {
        width: 100%;           /* 保持响应式宽度 */
        height: auto;          /* 保持原始比例 */
        border-radius: 6px;    /* 增大圆角半径 */
    }

    /* 图片说明文字调整 */
    .teaser-image p {
        font-size: 1.1rem;     /* 增大字体 */
        margin-top: 1.5rem;     /* 增加间距 */
    }
    
    /* 视频容器样式 */
    .slides-container {
        display: flex;
        transition: transform 0.5s ease-in-out;
    }

    .slider-button {
        position: absolute;
        top: 50%;
        transform: translateY(-50%);
        background: rgba(255,255,255,0.9);
        width: 40px;
        height: 40px;
        border-radius: 50%;
        display: flex;
        align-items: center;
        justify-content: center;
        box-shadow: 0 2px 8px rgba(0,0,0,0.1);
        border: 1px solid rgba(0,0,0,0.1);
        z-index: 10;
        cursor: pointer;
        transition: all 0.3s ease;
        margin: 0 5px;
    }

    .slider-button:hover {
        border-color: #3b82f6; /* 品牌蓝色 */
        color: #3b82f6;
        transform: translateY(-50%) scale(1.1);
        box-shadow: 0 4px 12px rgba(59, 130, 246, 0.1);
    }

    .slider-button:active {
        transform: translateY(-50%) scale(0.95);
    }


    .prev { left: 0px; }
    .next { right: 0px; }

    .video-section {
        position: relative;
        padding: 4rem 0; /* 保持与Bulma的section一致 */
        background: #f8f9fa; /* 可选背景色 */
    }

    .video-slider {
        position: relative;
        max-width: 800px;
        margin: 0 auto;
        /* padding: 0 60px;  为按钮留出空间 */
        overflow: hidden; /* 添加溢出隐藏 */
    }

    .video-slide {
      min-width: 0; /* 占位，JS 会覆盖 */
      max-width: none;
      flex: 0 0 auto;
    }

    /* 视频元素样式 */
    video {
        width: 100%; /* 改为100%宽度 */
        height: auto; /* 增加最大高度 */
        object-fit: contain; /* 保持比例 */
    }

    .slide-item {
      display: flex;
      flex-direction: column;
      align-items: center;
      text-align: center;
    }
    .slide-item video {
      width: 80%;
      height: auto;
      object-fit: contain;
      background: black;
    }
    .slide-extra {
      margin-top: 0.75rem;
      width: 100%;
    }
    .slide-extra img {
      max-width: 80%;
      height: auto;
      border-radius: 4px;
    }
    .slide-extra p {
      font-size: 0.9rem;
      margin-top: 0.5rem;
      color: #555;
    }

    /* dots 容器 居中，给点与点之间留白 */
    .slider-dots {
      display: flex;
      justify-content: center;
      margin-top: 1rem;
      gap: 0.5rem;
    }

    /* 单个小点 */
    .slider-dot {
      width: 5px;
      height: 5px;
      background: #ccc;
      border-radius: 50%;
      transition: transform 0.3s, background 0.3s;
      cursor: pointer;
    }

    /* 当前激活的小点 */
    .slider-dot.active {
      background: #3b82f6;
      transform: scale(1.2);
    }

    /* 响应式调整 */
    @media (max-width: 768px) {
    /* 1) 外层仍然隐藏超出，保持横向滑动机制 */
    .video-slider {
      height: auto !important;
      max-height: none !important;
    }

    /* 2) 滑动容器继续 flex 布局 */
    .slides-container {
      display: flex !important;
      transition: transform 0.5s ease-in-out;
    }
    
    /* 3) 每个 slide 占满整个可视宽度 */
    .slide-item {
      padding: 0 !important;
    }
  }
  </style>
</head>

<body>
  <!-- 简化Header部分 -->
  <section class="section">
    <div class="content-block has-text-centered">
      <h1 class="title paper-title has-text-centered">
        DualReal:<br>Adaptive Joint Training for Lossless<br>Identity-Motion Fusion in Video Customization
      </h1>

      <div class="content-block" style="margin-bottom: 5px; margin-top: -10px;">
        <span class="author-block">
            <sup style="color: rgba(182, 47, 47, 0.874); font-size: 1.7rem; font-weight: bold; font-family: 'Google Sans';">ICCV 2025</sup>
        </span>
      </div>
      
      <div class="author-list has-text-centered">
        <span>
          <a href="mailto:wenc_k@mail.ustc.edu.cn" target="_blank">Wenchuan Wang</a>,
        </span>
        <span>
          <a href="mailto:huangmq@mail.ustc.edu.cn" target="_blank">Mengqi Huang</a>,
        </span>
        <span>
          <a href="mailto:tuyijing@mail.ustc.edu.cn" target="_blank">Yijing Tu</a>,
        </span>
        <span>
          <a href="mailto:zdmao@ustc.edu.cn" target="_blank">Zhendong Mao</a><sup>*</sup>
        </span>
        <div class="institution mt-2">
          University of Science and Technology of China,
        </div>
        <div class="institution mt-2">
          <sup>*</sup>Corresponding author
        </div>
      </div>

      <!-- 简化按钮 -->
      <div class="buttons is-centered are-medium">
        <a href="https://arxiv.org/pdf/2505.02192" class="button is-rounded">
          <span class="icon"><i class="fas fa-file-pdf"></i></span>
          <span>Paper</span>
        </a>
        <a href="https://github.com/wenc-k/DualReal" class="button is-rounded is-dark">
          <span class="icon"><i class="fab fa-github"></i></span>
          <span>Code</span>
        </a>
        <a href="https://arxiv.org/abs/2505.02192" class="button is-rounded is-dark">
          <span class="icon"><i class="ai ai-arxiv"></i></span>
          <span>Arxiv</span>
        </a>
      </div>

      <!-- 新增展示图区块 -->
      <div class="teaser-image" style="margin: 3rem auto 2rem; max-width: 1400px;">
        <img src="./img/result.png" 
             alt="DualReal Result Showcase"
             style="width: 100%; 
                    height: auto;
                    border-radius: 4px;">
        <p>
        Generated customization results of our proposed novel paradigm DualReal. Given subject images and motion videos, DualReal generates high-quality customized identity and motion simultaneously, without compromising the consistency of either dimension.
        </p>
      </div>
    </div>
  </section>

  <!-- 摘要部分 -->
  <section class="section" style="background: #f8f9fa;">
    <div class="content-block">
      <h2 class="title is-3 has-text-centered">Abstract</h2>
      <div class="content">
        <p>
            Customized text-to-video generation with pre-trained large-scale models has recently garnered significant attention through focusing on identity and motion consistency. Existing works typically follow the isolated customized paradigm, where the subject identity or motion dynamics are customized exclusively. However, this paradigm completely ignores the intrinsic mutual constraints and synergistic interdependencies between identity and motion, resulting in identity-motion conflicts throughout the generation process that systematically degrades. To address this, we introduce DualReal, a novel framework that, employs adaptive joint training to collaboratively construct interdependencies between dimensions. Specifically, DualReal is composed of two units: (1) Dual-aware Adaptation dynamically selects a training phase (i.e., identity or motion), learns the current information guided by the frozen dimension prior, and employs a regularization strategy to avoid knowledge leakage; (2) StageBlender Controller leverages the denoising stages and Diffusion Transformer depths to guide different dimensions with adaptive granularity, avoiding conflicts at various stages and ultimately achieving lossless fusion of identity and motion patterns. We constructed a more comprehensive evaluation benchmark than existing methods. The experimental results show that DualReal improves CLIP-I and DINO-I metrics by 21.7% and 31.8% on average, and achieves top performance on nearly all motion quality metrics.
        </p>
      </div>
    </div>
  </section>

  <!-- 方法图示 -->
  <section class="section">
    <div class="content-block">
      <h2 class="title is-3 has-text-centered">How does it work?</h2>
      <div class="has-text-centered">
        <img src="./img/pipeline.png" 
        alt="DualReal Pipeline"
        style="width: 100%; 
                height: auto;
                border-radius: 4px;">
      </div>
      <div class="content mt-4">
        <p> 
            <b>Training Paradigm:</b> At each training step, we first dynamically select the training phase Z(i.e., identity or motion) to determine the data processing path. The specific data undergoes noise injection and combines with the text embeddings. StageBlender Controller governs two-dimension adapters' contributions in Dual-Aware Block (DA-Block) through time-aware conditioning of current denoising step and fused feature representations. In DA-Block, the training-stage(Z) adapter learns the current information guided by the frozen dimension prior, and employs a regularization strategy to avoid dimensional knowledge leakage, achieving joint training. Both branches engage in residual connections with DiT outputs.  
        </p>
      </div>
      <div class="has-text-centered">
        <img src="./img/pipeline-2.png" 
        alt="DualReal Pipeline"
        style="width: 60%; 
                height: auto;
                border-radius: 4px;">
      </div>
      <div class="content mt-4">
        <p> 
            <b>StageBlender Controller</b> employs Adaptive LayerNorm mechanism  modulates text-visual feature based on timestep-conditional embeddings, then maps the feature to multiple groups after residual gated connections. These scaled weight are subsequently routed to their respective DA-Blocks for processing.
        </p>
      </div>
    </div>
  </section>

  <!-- 对比结果 -->
  <section class="section">
    <div class="content-block">
      <h2 class="title is-3 has-text-centered">Comparison Results</h2>
      <div class="has-text-centered">
        <img src="./img/mainresult.png" 
        alt="DualReal Pipeline"
        style="width: 100%; 
                height: auto;
                border-radius: 4px;">
      </div>
      <div class="content mt-4">
        <p> 
            <b>Qualitative comparison with existing methods.</b> Compared with other methods, DualReal achieves high identity consistency with coherent motion, demonstrating the advantage of joint training in balancing pattern conflicts.
        </p>
      </div>

      <div class="has-text-centered">
        <img src="./img/exp_png.png" 
        alt="DualReal Pipeline"
        style="width: 100%; 
                height: auto;
                border-radius: 4px;">
      </div>
      <div class="content mt-4">
        <p> 
          <b>Quantitative comparison of personalization video generation for customized subject and motion.</b> "T.Cons" and "T.Flickering" denotes Temporal Consistency and Temporal Flickering, respectively. Compared with other methods, DualReal achieved average improvements of <b>21.7%</b> on CLIP-I and <b>31.8%</b> on DINO-I, recorded the best results on three motion quality metrics (T.Cons, Motion Smoothness, and Temporal Flickering), and ranked second on CLIP-T. The motion datasets achieve an average Dynamic Degree of <b>12.02</b> and parenthetical values quantify the current method’s deviation from this benchmark to determine the intensity consistency of movement.
        </p>
      </div>
    </div>
  </section>

  <!-- 轮播容器改为 section -->
  <section class="section video-section" style="background: #f8f9fa;">
    <div class="container">
        <h2 class="title is-3 has-text-centered">More Results</h2>
        <!-- 视频容器保留原有结构 -->
        <div class="video-slider">
            <div class="slides-container" id="slidesContainer">
                <div class="slide-item">
                  <video controls>
                    <source src="videos/case3.mp4" type="video/mp4">
                  </video>
                  <div class="slide-extra">
                    <p>Plushie penguin * is skateboarding with flippers through autumn pumpkin patches</p>
                  </div>
                </div>
                <div class="slide-item">
                  <video controls>
                    <source src="videos/case5.mp4" type="video/mp4">
                  </video>
                  <div class="slide-extra">
                    <p>Dog * wearing a knitted sweater in a cozy fireplace cabin is playing guitar</p>
                  </div>
                </div>
                <div class="slide-item">
                  <video controls>
                    <source src="videos/case8.mp4" type="video/mp4">
                  </video>
                  <div class="slide-extra">
                    <p>Toy gnome * is doing TaiChi, flowing through a slow, meditative sequence</p>
                  </div>
                </div>
                <div class="slide-item">
                  <video controls>
                    <source src="videos/case10.mp4" type="video/mp4">
                  </video>
                  <div class="slide-extra">
                    <p>Plushie redbear * in tactical vest is surfing, gliding smoothly across curling waves</p>
                  </div>
                </div>
                <div class="slide-item">
                  <video controls>
                    <source src="videos/case2.mp4" type="video/mp4">
                  </video>
                  <div class="slide-extra">
                    <p>Plushie wolf * is skiing carving fresh powder trails with expert balance</p>
                  </div>
                </div>
                <div class="slide-item">
                  <video controls>
                    <source src="videos/case6.mp4" type="video/mp4">
                  </video>
                  <div class="slide-extra">
                    <p>Dog * with a diamond-studded collar in a grand ballroom is playing guitar</p>
                  </div>
                </div>
                <div class="slide-item">
                  <video controls>
                    <source src="videos/case17.mp4" type="video/mp4">
                  </video>
                  <div class="slide-extra">
                    <p>Dog * is playing flute in a retro diner booth wearing a paper crown and ketchup-stained apron</p>
                  </div>
                </div>
                <div class="slide-item">
                  <video controls>
                    <source src="videos/case20.mp4" type="video/mp4">
                  </video>
                  <div class="slide-extra">
                    <p>Plushie bunny * sporting a golden crown in a marble palace is doing bench press, steadily lifting the barbell with focused determination</p>
                  </div>
                </div>
            </div>
            <!-- 导航按钮 -->
            <button class="slider-button prev">
              <svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2">
                  <path stroke-linecap="round" stroke-linejoin="round" d="M15 19l-7-7 7-7"/>
              </svg>
            </button>

            <button class="slider-button next">
              <svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2">
                  <path stroke-linecap="round" stroke-linejoin="round" d="M9 5l7 7-7 7"/>
              </svg>
            </button>

            <!-- 进度指示小点 -->
            <div class="slider-dots" id="sliderDots"></div>
        </div>
    </div>
  </section>

  <section class="section" style="background: #f8f9fa;">
    <div class="content-block">
      <h2 class="title is-3 has-text-centered">Citation</h2>
      <pre style="background: #fff; padding: 1.5rem; border-radius: 4px;"><code>@article{wang2025dualreal,
        title={DualReal: Adaptive Joint Training for Lossless Identity-Motion Fusion in Video Customization},
        author={Wang, Wenchuan and Huang, Mengqi and Tu, Yijing and Mao, Zhendong},
        journal={arXiv preprint arXiv:2505.02192},
        year={2025}
      }</code></pre>
    </div>
  </section>

  <footer class="footer">
    <div class="container">
      <div class="columns is-centered">
        <div class="column is-8">
          <div class="content">
  
            <p>
              This page was built using the <a href="https://github.com/eliahuhorwitz/Academic-project-page-template" target="_blank">Academic Project Page Template</a> which was adopted from the <a href="https://nerfies.github.io" target="_blank">Nerfies</a> project page.
              You are free to borrow the source code of this website, we just ask that you link back to this page in the footer. <br> This website is licensed under a <a rel="license"  href="http://creativecommons.org/licenses/by-sa/4.0/" target="_blank">Creative
              Commons Attribution-ShareAlike 4.0 International License</a>.
            </p>
  
          </div>
        </div>
      </div>
    </div>
  </footer>

  <!-- 基础脚本 -->
  <script defer src="https://use.fontawesome.com/releases/v5.3.1/js/all.js"></script>
  <script>
  document.addEventListener('DOMContentLoaded', () => {
    const slider    = document.querySelector('.video-slider');
    const container = document.querySelector('#slidesContainer');
    const slides    = Array.from(document.querySelectorAll('.slide-item'));
    const prevBtn   = document.querySelector('.prev');
    const nextBtn   = document.querySelector('.next');
    const dotsWrap  = document.querySelector('#sliderDots');
    let currentIndex = 0;

    const getSlideWidth = () => slider.clientWidth;

    // 渲染 slider 和 slide 宽度
    function initSlider() {
      const w = getSlideWidth();
      slides.forEach(s => {
        s.style.minWidth = `${w}px`;
        s.style.maxWidth = `${w}px`;
      });
      container.style.width = `${w * slides.length}px`;
      initDots();      // ← 初始化小点
      updateSlider();  // ← 更新位置 & 高亮小点
    }

    // 创建小点
    function initDots() {
      dotsWrap.innerHTML = ''; // 先清空
      slides.forEach((_, idx) => {
        const dot = document.createElement('div');
        dot.classList.add('slider-dot');
        dot.addEventListener('click', () => {
          currentIndex = idx;
          updateSlider();
        });
        dotsWrap.appendChild(dot);
      });
    }

    // 移动 slider 并高亮对应小点
    function updateSlider() {
      const w = getSlideWidth();
      container.style.transform = `translateX(-${currentIndex * w}px)`;
      // 更新小点
      const allDots = dotsWrap.querySelectorAll('.slider-dot');
      allDots.forEach((d, i) => {
        d.classList.toggle('active', i === currentIndex);
      });
    }

    prevBtn.addEventListener('click', () => {
      if (currentIndex > 0) currentIndex--, updateSlider();
    });
    nextBtn.addEventListener('click', () => {
      if (currentIndex < slides.length - 1) currentIndex++, updateSlider();
    });

    window.addEventListener('resize', initSlider);
    initSlider();
  });
  </script>
</body>
</html>